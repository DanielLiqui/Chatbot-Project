# Chatbot Project
FastAPI Â· NLP Â· React (Vite)

---

## ğŸš€ Tech Stack

### Backend
- Python 3.10+
- FastAPI
- scikit-learn

### Frontend
- React
- Vite
- Fetch API

---

## ğŸ“ Project Structure

chatbot/
â”œâ”€â”€ app/                  # Backend (FastAPI)
â”‚   â”œâ”€â”€ api/              # API routes
â”‚   â”œâ”€â”€ nlp/              # NLP model & inference
â”‚   â”œâ”€â”€ services/         # Business logic (responses)
â”‚   â”œâ”€â”€ schemas/          # Pydantic schemas
â”‚   â””â”€â”€ main.py           # FastAPI entry point
â”‚
â”œâ”€â”€ data/                 # Training datasets
â”‚
â”œâ”€â”€ frontend/             # React frontend (Vite)
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## Installation

### Download repozitory

First, download the project from GitHub:

git clone https://github.com/DanielLiqui/Chatbot-Project.git


## âš™ï¸ Backend Setup (FastAPI)

### 1ï¸âƒ£ Create virtual environment

From project root:

python -m venv venv

Activate it:

Linux / macOS  
source venv/bin/activate

Windows  
venv\Scripts\activate

---

### 2ï¸âƒ£ Install dependencies

pip install -r requirements.txt

---

### 3ï¸âƒ£ Run backend server

uvicorn app.main:app --reload

Backend will be available at:
- API â†’ http://127.0.0.1:8000
- Swagger â†’ http://127.0.0.1:8000/docs

---

## ğŸ’¬ Frontend Setup (React + Vite)

### 1ï¸âƒ£ Go to frontend directory

cd frontend

---

### 2ï¸âƒ£ Install frontend dependencies

npm install

---

### 3ï¸âƒ£ Run frontend dev server

npm run dev

Frontend will be available at:
- http://localhost:5173

âš ï¸ Backend must be running for the chat to work

---

## ğŸ” Local Development Flow

Terminal 1:
uvicorn app.main:app --reload

Terminal 2:
cd frontend  
npm run dev

Open browser:
http://localhost:5173

---

## ğŸ§  NLP Inference Flow

1. User sends message from frontend
2. /chat endpoint receives request
3. NLP model predicts intent and confidence
4. Response is selected from dictionary based on intent
5. Backend returns structured response to frontend

---

## ğŸ“¡ API Example

POST /chat

Request:
{
  "message": "Where is my order?"
}

Response:
{
  "intent": "track_order",
  "confidence": 0.52,
  "response": "You can track your order using the tracking link."
}

---

## ğŸ§ª Notes for Developers

- NLP model is loaded once at startup
- Responses are rule-based (dictionary-driven)
- Model training is decoupled from inference
- Frontend uses native fetch API

---

## ğŸš§ Roadmap

- Confidence-based fallback
- Clarification questions
- Multi-language support
- Generative response model
- Docker & docker-compose setup

---

## ğŸ§© Known Limitations

- No authentication
- No persistent chat history
- Open CORS (development only)
